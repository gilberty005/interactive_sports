Metadata-Version: 2.4
Name: fantasy-agent-eval
Version: 0.1.0
Summary: Tool-using NHL fantasy agent scaffold (Phase A).
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: requests>=2.31.0
Requires-Dist: python-dotenv>=1.0.1
Provides-Extra: dev
Requires-Dist: pytest>=7.4.0; extra == "dev"
Provides-Extra: openai
Requires-Dist: openai>=1.40.0; extra == "openai"
Provides-Extra: gemini
Requires-Dist: google-generativeai>=0.7.0; extra == "gemini"
Provides-Extra: anthropic
Requires-Dist: anthropic>=0.32.0; extra == "anthropic"
Provides-Extra: llm
Requires-Dist: openai>=1.40.0; extra == "llm"
Requires-Dist: google-generativeai>=0.7.0; extra == "llm"
Requires-Dist: anthropic>=0.32.0; extra == "llm"

# Fantasy Agent Eval (Phase A)

This repo contains a minimal, tool-using NHL fantasy agent scaffold. The agent is grounded: it must call tools for schedules and game logs, and returns a strict JSON final answer with a trace of data used.

## Structure

- `prompts/system_prompt_v0.md`: system prompt, treated as code.
- `src/agent/`: prompt loading and agent loop.
- `src/tools/`: NHL API client and tool implementations.
- `src/data/`: cache and normalization helpers.
- `tests/`: smoke tests for tool calls.

## Quickstart

Install deps:

```
pip install -e .[dev]
```

Run tests (networked):

```
pytest -m network
```

## Run the agent

Install a provider SDK:

```
pip install -e .[llm]
```

Set an API key:

- OpenAI: `export OPENAI_API_KEY=...`
- Gemini: `export GEMINI_API_KEY=...` (or `GOOGLE_API_KEY`)
- Anthropic: `export ANTHROPIC_API_KEY=...`

Run a query:

```
python -m src.agent.cli --provider openai --model gpt-4o-mini "How many games does Toronto play Jan 22â€“28, 2024?"
```

## Notes

- The agent loop in `src/agent/runner.py` is provider-agnostic; plug in an LLM client that implements the `generate()` protocol.
- The tools call the NHL Stats API and cache responses on disk under `.cache/nhl_api/`.
# interactive_sports
